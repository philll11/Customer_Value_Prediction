{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Load libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import scipy\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets.\n",
    "path = '../input/santander-value-prediction-challenge/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was created by https://www.kaggle.com/rinnqd. \\\n",
    "# Reference: https://www.kaggle.com/rinnqd/reduce-memory-usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop([\"ID\", \"target\"], axis=1)\n",
    "y = train[\"target\"].values\n",
    "\n",
    "test = test.drop([\"ID\"], axis=1)\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 256 Constant Columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removes features containing constant values\n",
    "y = train['target'].copy()\n",
    "train = train.drop(['target','ID'], axis=1)\n",
    "\n",
    "feat_to_remove = []\n",
    "for feat in train.columns:\n",
    "    if len(train[feat].unique()) == 1:\n",
    "        feat_to_remove.append(feat)\n",
    "        \n",
    "train.drop(feat_to_remove, axis=1, inplace=True)\n",
    "\n",
    "test.drop(feat_to_remove, axis=1, inplace=True)\n",
    "\n",
    "print(f'Removed {len(feat_to_remove)} Constant Columns\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training features: 4735 | Number of training rows: 4459\n",
      "##########################################################################\n",
      "\n",
      "Parameters being tested: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.5}\n",
      "[0]\teval-rmse:13.9511\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1000]\teval-rmse:1.4714\n",
      "Stopping. Best iteration:\n",
      "[1506]\teval-rmse:1.46148\n",
      "\n",
      "Execution time: 10.13s\n",
      "\n",
      "------------------------------------\n",
      "[0]\teval-rmse:13.9247\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1000]\teval-rmse:1.52323\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-f7a8f2fd5b17>\u001b[0m in \u001b[0;36mGridSearch\u001b[0;34m(hyperParams, train_df, target)\u001b[0m\n\u001b[1;32m     52\u001b[0m                             \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                             )    \n\u001b[1;32m     56\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 3 month period\n",
    "train_3_period_smooth = train.rolling(3,axis=1).mean()\n",
    "test_3_period_smooth = test.rolling(3,axis=1).mean()\n",
    "# train_3_period_smooth.fillna(0, axis=1, inplace=True)\n",
    "\n",
    "# ## 6 month period\n",
    "# train_6_period_smooth = train.rolling(6,axis=1).mean()\n",
    "# test_6_period_smooth = test.rolling(6,axis=1).mean()\n",
    "# # train_6_period_smooth.fillna(0, axis=1, inplace=True)\n",
    "\n",
    "# ## 12 month period\n",
    "# train_12_period_smooth = train.rolling(12,axis=1).mean()\n",
    "# test_12_period_smooth = test.rolling(12,axis=1).mean()\n",
    "# # train_12_period_smooth.fillna(0, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# ## 7-day period\n",
    "# train_7_period_smooth = train.rolling(7,axis=1).mean()\n",
    "# test_7_period_smooth = test.rolling(7,axis=1).mean()\n",
    "# # train_7_period_smooth.fillna(0, axis=1, inplace=True)\n",
    "\n",
    "# ## 30-day period\n",
    "# train_30_period_smooth = train.rolling(30,axis=1).mean()\n",
    "# test_30_period_smooth = test.rolling(30,axis=1).mean()\n",
    "# # train_30_period_smooth.fillna(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Preparing mean smoothing training data\n",
    "X_3mms = train_3_period_smooth\n",
    "y_3mms = np.log1p(y)\n",
    "# X_6mms = train_6_period_smooth\n",
    "# y_6mms = np.log1p(y)\n",
    "# X_12mms = train_12_period_smooth\n",
    "# y_12mms = np.log1p(y)\n",
    "\n",
    "# X_7dms = train_7_period_smooth\n",
    "# y_7dms = np.log1p(y)\n",
    "# X_30dms = train_30_period_smooth\n",
    "# y_30dms = np.log1p(y)\n",
    "\n",
    "## Preparing sum truncation training data\n",
    "# X_3m_sum = train_3_period_sum\n",
    "# y_3m_sum = np.log1p(y)\n",
    "# X_6m_sum = train_6_period_sum\n",
    "# y_6m_sum = np.log1p(y)\n",
    "# X_12m_sum = train_12_period_sum\n",
    "# y_12m_sum = np.log1p(y)\n",
    "\n",
    "# X_7d_sum = train_7_period_sum\n",
    "# y_7d_sum = np.log1p(y)\n",
    "# X_30d_sum = train_30_period_sum\n",
    "# y_30d_sum = np.log1p(y)\n",
    "\n",
    "## Preparing test data\n",
    "test = test.drop([\"ID\"], axis=1)\n",
    "\n",
    "\n",
    "del train, train_no_zero, train_3_period_smooth, train_6_period_smooth, train_12_period_smooth, train_7_period_smooth,\n",
    "train_30_period_smooth, train_3_period_sum, train_6_period_sum, train_12_period_sum, train_7_period_sum, \n",
    "train_30_period_sum\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dMatrix(X, y=None):\n",
    "    if y is None:\n",
    "        return xgb.DMatrix(X)\n",
    "    else:\n",
    "        return xgb.DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_set(X_val, y_val):\n",
    "    return [(xgb.DMatrix(X_val, y_val), 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBCV(X_data, y_data, model_params, folds_n):\n",
    "    folds = KFold(n_splits=folds_n, shuffle=True, random_state=42)\n",
    "    kfold_gs_score=0\n",
    "    for train_index, test_index in folds.split(X_data):\n",
    "    #    Seperate train/test data\n",
    "        train_X, train_y = X_data.loc[train_index], y_data[train_index]\n",
    "        test_X, test_y = X_data.loc[test_index], y_data[test_index]\n",
    "\n",
    "    #    Preparing the training data\n",
    "        eval_set_list = create_eval_set(test_X, test_y)\n",
    "        dMatTrain = to_dMatrix(train_X, train_y)\n",
    "        dMatTest = to_dMatrix(test_X)          \n",
    "\n",
    "    #    Training the model\n",
    "        gs = xgb.train(\n",
    "                        params=model_params, \n",
    "                        dtrain=dMatTrain, \n",
    "                        num_boost_round=5000, \n",
    "                        evals=eval_set_list,\n",
    "                        early_stopping_rounds=100, \n",
    "                        verbose_eval=False\n",
    "                        )\n",
    "\n",
    "        pred_y = np.expm1(gs.predict(dMatTest))\n",
    "\n",
    "    #    Sum kfold model score\n",
    "        kfold_gs_score += np.sqrt(metrics.mean_squared_error(np.expm1(test_y), pred_y))\n",
    "\n",
    "    # Produce average model score\n",
    "    gs_score = kfold_gs_score / folds_n\n",
    "    return gs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data\n",
    "best_params = {'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8999999999999999}\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eta':0.01,\n",
    "    'eval_metric':'rmse',\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "params.update(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A collection of all model scores\n",
    "scores = {}\n",
    "idx = []\n",
    "\n",
    "# Mean smoothing features\n",
    "scores['ms3'] = XGBCV(X_3mms, y_3mms, params, 5)\n",
    "# scores['ms6'] = XGBCV(X_6mms, y_6mms, params, 5)\n",
    "# scores['ms12'] = XGBCV(X_12mms, y_12mms, params, 5)\n",
    "\n",
    "# scores['ms7'] = XGBCV(X_7dms, y_7dms, params, 5)\n",
    "# scores['ms30'] = XGBCV(X_30dms, y_30dms, params, 5)\n",
    "\n",
    "# del x_log, y_log\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model\n",
    "Now that we have found our best parameters, we can train our final model and submit to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_3mms, y_3mms, test_size=0.25, random_state=42)\n",
    "\n",
    "# Eval_set train/test preformance data\n",
    "dX_train = xgb.DMatrix(X_train, y_train)\n",
    "dy_test = xgb.DMatrix(X_test, y_test)\n",
    " \n",
    "# Training data\n",
    "dtrain = xgb.DMatrix(X, y)\n",
    "\n",
    "# del X_train, X_test, y_train, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-58d9dabfc916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test)\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:13.9626\teval-rmse:13.9538\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1000]\ttrain-rmse:1.12053\teval-rmse:1.10625\n",
      "[2000]\ttrain-rmse:0.993619\teval-rmse:0.985007\n",
      "[3000]\ttrain-rmse:0.908328\teval-rmse:0.900145\n",
      "[4000]\ttrain-rmse:0.84454\teval-rmse:0.835424\n",
      "[4999]\ttrain-rmse:0.794802\teval-rmse:0.78424\n"
     ]
    }
   ],
   "source": [
    "# original algorithm\n",
    "best_params = {'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8999999999999999}\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eta':0.01,\n",
    "    'eval_metric':'rmse',\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "# params.update(best_params)\n",
    "\n",
    "eval_set = [(dX_train, 'train'), (dy_test, 'eval')]\n",
    "bst = xgb.train(\n",
    "                params=params, \n",
    "                dtrain=dtrain, \n",
    "                num_boost_round=5000, \n",
    "                evals=eval_set,\n",
    "                early_stopping_rounds=100, \n",
    "                verbose_eval=1000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(bst.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "sub['target'] = y_pred\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
